\textcolor{red}{\textbf{Conceitos trabalhados}: estimador de Bayes; perda; estimador de máxima verossimilhança.}
\textcolor{purple}{\textbf{Nível de dificuldade}: fácil.}\\
\textcolor{blue}{
\textbf{Resolução:}
Primeiro, vamos escrever a perda esperada:
\begin{align*}
    E_{\theta \mid \bx}\left[L(\delta, \theta\right] &= \sum_{t \in \Omega} L(\delta, t)\xi(t \mid \bx),\\
    &= \sum_{t^\star \neq \delta} \xi(t^\star \mid \bx),\\
    &= P_{\theta \mid \bx}(\theta \neq \delta).
\end{align*}
Deste modo, o estimador de Bayes é estimador que minimiza esta perda:
\begin{align*}
    \delta_{\textrm{MAP}} &= \argmin_{d \in \mathcal{D}} E_{\theta \mid \bx}\left[L(d, \theta)\right],\\
    &= \argmin_{d \in \Omega} P_{\theta \mid \bx}(\theta \neq d),\\
    &= \argmin_{d \in \Omega} \left\{ 1- P_{\theta \mid \bx}(\theta = d) \right\},\\
    &= \argmax_{d \in \Omega} P_{\theta \mid \bx}(\theta = d),\\
    &= \argmax_{d \in \Omega} \xi(d \mid \bx),
\end{align*}
como queríamos demonstrar.
Note que é natural fazer $\mathcal{D} = \Omega$ porque a perda é $1$ para todo valor fora de $\Omega$.
Para encontrar o EMV pedido em b), primeiro vamos formular um modelo probabilístico para os dados.
É razoável afirmar que o número de itens defeituosos tem distribuição binomial com $n$ tentativas e probabilidade de sucesso $\theta \in \{0.1, 0.2\}$, isto é, com um espaço paramétrico discreto em lugar do usual $\Omega = (0, 1)$:
\begin{equation*}
    f(x \mid n, \theta) = \binom{n}{x} \theta^{x} (1-\theta)^{n-x}, \theta \in \left\{\frac{1}{10}, \frac{2}{10}\right\}, x = 0, 1, \ldots, n. 
\end{equation*}
Assim, temos que 
\begin{align*}
     \delta_{\textrm{EMV}} &= \argmax_{\theta \in \left\{\frac{1}{10}, \frac{2}{10}\right\}} \binom{n}{x} \theta^{x} (1-\theta)^{n-x},\\
          &= \argmax_{\theta \in \left\{\frac{1}{10}, \frac{2}{10}\right\}} \theta^{x} (1-\theta)^{n-x}.
\end{align*}
Poderíamos parar por aqui, mas vamos explorar essa questão mais um pouco.
Escreva $f_1(x) = f(x \mid n, 0.1)$ e $f_2(x) = f(x \mid n, 0.2)$ e note que
\begin{equation*}
    r(x) := \frac{f_1(x)}{f_2(x)} < 1 \iff \delta_{\textrm{EMV}} = 0.2.
\end{equation*}
Reescrevendo a verossimilhança como  $f(x \mid n, \theta) \propto (\frac{\theta}{1-\theta})^x(1-\theta)^n$ , temos
\begin{align*}
    \frac{(\frac{1}{9})^x(\frac{9}{10})^n}{(\frac{1}{4})^x(\frac{8}{10})^n} < 1 \iff \delta_{\textrm{EMV}} = 0.2,\\
    \left(\frac{4}{9}\right)^x\left(\frac{9}{8}\right)^n < 1 \iff \delta_{\textrm{EMV}} = 0.2,\\
    \frac{\log\left(\frac{4}{9}\right)}{\log\left(\frac{9}{8}\right)} < -\frac{n}{x} \iff \delta_{\textrm{EMV}} = 0.2,\\
        \frac{n}{x} > 6.884949 \iff \delta_{\textrm{EMV}} = 0.2,
\end{align*}
com o compromisso de que vamos definir $n/0 = \infty > 6.884949$.
Agora vamos resolver c), computando primeiro a distribuição \textit{a posteriori} de $\theta$:
\begin{align*}
    \xi(\theta = 0.1 \mid \bx) &= \frac{f_1(x)\pi(0.1)}{f_1(x)\pi(0.1) + f_2(x)[1-\pi(0.1)]},\\
    &= \frac{0.7\left(\frac{1}{10}\right)^x \left(\frac{9}{10}\right)^n}{0.7\left(\frac{1}{10}\right)^x \left(\frac{9}{10}\right)^n + 0.3\left(\frac{2}{10}\right)^x \left(\frac{8}{10}\right)^n}.
\end{align*}
Fazendo $\pi_1 = \pi(0.1)$ e $\pi_2 = \pi(0.2)$, temos que de modo análogo ao que foi feito para o EMV: 
\begin{align*}
\frac{\xi(\theta = 0.1 \mid \bx)}{  \xi(\theta = 0.2 \mid \bx)}< 1 \iff \delta_{\textrm{MAP}} = 0.2,\\
\frac{f_1(x)\pi_1}{f_2(x)\pi_2}< 1 \iff \delta_{\textrm{MAP}} = 0.2,\\
\frac{f_1(x)}{f_2(x)}\frac{\pi_1}{1-\pi_1}< 1 \iff \delta_{\textrm{MAP}} = 0.2,\\
  \left(\frac{4}{9}\right)^x\left(\frac{9}{8}\right)^n \times \frac{7}{3}< 1 \iff \delta_{\textrm{MAP}} = 0.2,
\end{align*}
ou seja, a razão de verossimilhanças precisa ser ajustada pela razão entre as probabilidades \textit{a priori}, ou \textit{chance} \textit{a priori} neste caso ($k=2$).
Por exemplo, quando $x=3$, $\delta_{\textrm{EMV}} = 0.2$, mas $\delta_{\textrm{MAP}}  = 0.1$.
$\blacksquare$\\
\textbf{Comentário:}
Esta questão se baseia no exercício 2 da seção 7.2 de De Groot (recomendado!) e exercício de revisão feito em aula.
Neste exercício nós aplicamos a definição de estimador de Bayes para de fato nos convencer de que, uma vez estabelecida uma função de perda e uma priori (e portanto, uma posteriori), somos sempre capazes de encontrar (pelo menos) um estimador de Bayes.
Além disso, vimos que é possível criar um estimador bayesiano que maximiza a posteriori em vez de integrar com respeito a ela, bem ao feitio da estatística clássica.
Note que adicionar uma distribuição sobre $\Omega$ pode e em geral vai levar a inferências diferentes do que se obteria puramente usando a verossimilhança.
}